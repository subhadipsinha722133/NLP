{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "741a3691",
   "metadata": {},
   "source": [
    "### Step 1 Lowercasing :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bba1521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is NLP:=>\\n\\nNatural language processing is a subfield of linguistics, computer science, and artificial intelligence\\nconcerned with the interactions between computers and human language, in particular how to\\nprogram computers to process and analyze large amounts of natural language data.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''What is NLP:=>\n",
    "\n",
    "Natural language processing is a subfield of linguistics, computer science, and artificial intelligence\n",
    "concerned with the interactions between computers and human language, in particular how to\n",
    "program computers to process and analyze large amounts of natural language data.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80de93da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a=pd.read_csv(r\"D:\\CODING\\PYTHON\\NLP\\IMDB Dataset_1.csv\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f993c939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bc4ff6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 row only lower case\n",
    "a[\"review\"][3].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee5549bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production. <br /><br />the...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically there's a family where a little boy ...\n",
       "4        petter mattei's \"love in the time of money\" is...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    i'm going to have to disagree with the previou...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All reviews in lower case\n",
    "a[\"review\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5532392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. <br /><br />the...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"review\"]=a[\"review\"].str.lower()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecc834e",
   "metadata": {},
   "source": [
    "### Step 2 Remove HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c1e5743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# def remove_html_tags(text):\n",
    "#     clean = re.compile('<.*?>')\n",
    "#     return re.sub(clean, '', text)\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    p=re.compile('<.*?>')\n",
    "    return p.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5506985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Movie 1 Actor - Aamir Khan Click here to download'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example:-----------------\n",
    "\n",
    "t=\"<html><body><p> Movie 1</p><p> Actor - Aamir Khan</p><p> Click here to <a href='http://google.com'>download</a></p></html></html>\"\n",
    "\n",
    "remove_html_tags(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4424e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production. the filming tec...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically there's a family where a little boy ...\n",
       "4        petter mattei's \"love in the time of money\" is...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    i'm going to have to disagree with the previou...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"review\"].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a84d4f",
   "metadata": {},
   "source": [
    "### Step 3 Remove URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0282cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    p=re.compile(r'http?//\\S+|www\\.S+')\n",
    "    return p.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0f34f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'Check out my notebook https://www.kaggle.com/campusx/notebook8223fc1abb'\n",
    "text2 = 'Check out my notebook http://www.kaggle.com/campusx/notebook8223fc1abb'\n",
    "text3 = 'Google search here www.google.com'\n",
    "text4 = 'For notebook click https://www.kaggle.com/campusx/notebook8223fclabb to search check www.google.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db76b8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For notebook click https://www.kaggle.com/campusx/notebook8223fclabb to search check www.google.com'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e8df3a",
   "metadata": {},
   "source": [
    "### Step 4 Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ef99bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string,time\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb909f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "pu=string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03efc74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    for i in pu:\n",
    "        text=text.replace(i,'')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e737a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= 'Hello, world! This is a test...?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "973b31e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world This is a test\n",
      "Time taken: 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "#  This is slow Technique\n",
    "start=time.time()\n",
    "print(remove_punctuation(text))\n",
    "time1=time.time()-start\n",
    "print(f\"Time taken: {time1*500000} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1284641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation_2(text):\n",
    "    # p=re.compile(r'[{}]'.format(exclude))\n",
    "    # return p.sub(r'',text)\n",
    "    return text.translate(str.maketrans('', '', pu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0035ecd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 50.258636474609375 seconds\n"
     ]
    }
   ],
   "source": [
    "# This is fast Technique\n",
    "start=time.time()\n",
    "remove_punctuation_2(text)\n",
    "time2=time.time()-start\n",
    "print(f\"Time taken: {time2*50000} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "888b3582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119237</td>\n",
       "      <td>105834</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 06:55:44 +0000 2017</td>\n",
       "      <td>@AppleSupport causing the reply to be disregar...</td>\n",
       "      <td>119236</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119238</td>\n",
       "      <td>ChaseSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Oct 11 13:25:49 +0000 2017</td>\n",
       "      <td>@105835 Your business means a lot to us. Pleas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119239</td>\n",
       "      <td>105835</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 13:00:09 +0000 2017</td>\n",
       "      <td>@76328 I really hope you all change but I'm su...</td>\n",
       "      <td>119238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119240</td>\n",
       "      <td>VirginTrains</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 10 15:16:08 +0000 2017</td>\n",
       "      <td>@105836 LiveChat is online at the moment - htt...</td>\n",
       "      <td>119241</td>\n",
       "      <td>119242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119241</td>\n",
       "      <td>105836</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 10 15:17:21 +0000 2017</td>\n",
       "      <td>@VirginTrains see attached error message. I've...</td>\n",
       "      <td>119243</td>\n",
       "      <td>119240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>119330</td>\n",
       "      <td>105859</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 13:50:42 +0000 2017</td>\n",
       "      <td>@105860 I wish Amazon had an option of where I...</td>\n",
       "      <td>119329</td>\n",
       "      <td>119331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>119331</td>\n",
       "      <td>105860</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 13:47:14 +0000 2017</td>\n",
       "      <td>They reschedule my shit for tomorrow https://t...</td>\n",
       "      <td>119330</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>119332</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Oct 11 13:34:06 +0000 2017</td>\n",
       "      <td>@105861 Hey Sara, sorry to hear of the issues ...</td>\n",
       "      <td>119333</td>\n",
       "      <td>119334.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>119333</td>\n",
       "      <td>105861</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 14:05:18 +0000 2017</td>\n",
       "      <td>@Tesco bit of both - finding the layout cumber...</td>\n",
       "      <td>119335,119336</td>\n",
       "      <td>119332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>119335</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Oct 11 15:38:07 +0000 2017</td>\n",
       "      <td>@105861 If that doesn't help please DM your fu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119333.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    tweet_id     author_id  inbound                      created_at  \\\n",
       "0     119237        105834     True  Wed Oct 11 06:55:44 +0000 2017   \n",
       "1     119238  ChaseSupport    False  Wed Oct 11 13:25:49 +0000 2017   \n",
       "2     119239        105835     True  Wed Oct 11 13:00:09 +0000 2017   \n",
       "3     119240  VirginTrains    False  Tue Oct 10 15:16:08 +0000 2017   \n",
       "4     119241        105836     True  Tue Oct 10 15:17:21 +0000 2017   \n",
       "..       ...           ...      ...                             ...   \n",
       "88    119330        105859     True  Wed Oct 11 13:50:42 +0000 2017   \n",
       "89    119331        105860     True  Wed Oct 11 13:47:14 +0000 2017   \n",
       "90    119332         Tesco    False  Wed Oct 11 13:34:06 +0000 2017   \n",
       "91    119333        105861     True  Wed Oct 11 14:05:18 +0000 2017   \n",
       "92    119335         Tesco    False  Wed Oct 11 15:38:07 +0000 2017   \n",
       "\n",
       "                                                 text response_tweet_id  \\\n",
       "0   @AppleSupport causing the reply to be disregar...            119236   \n",
       "1   @105835 Your business means a lot to us. Pleas...               NaN   \n",
       "2   @76328 I really hope you all change but I'm su...            119238   \n",
       "3   @105836 LiveChat is online at the moment - htt...            119241   \n",
       "4   @VirginTrains see attached error message. I've...            119243   \n",
       "..                                                ...               ...   \n",
       "88  @105860 I wish Amazon had an option of where I...            119329   \n",
       "89  They reschedule my shit for tomorrow https://t...            119330   \n",
       "90  @105861 Hey Sara, sorry to hear of the issues ...            119333   \n",
       "91  @Tesco bit of both - finding the layout cumber...     119335,119336   \n",
       "92  @105861 If that doesn't help please DM your fu...               NaN   \n",
       "\n",
       "    in_response_to_tweet_id  \n",
       "0                       NaN  \n",
       "1                  119239.0  \n",
       "2                       NaN  \n",
       "3                  119242.0  \n",
       "4                  119240.0  \n",
       "..                      ...  \n",
       "88                 119331.0  \n",
       "89                      NaN  \n",
       "90                 119334.0  \n",
       "91                 119332.0  \n",
       "92                 119333.0  \n",
       "\n",
       "[93 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=pd.read_csv(r\"D:\\CODING\\PYTHON\\NLP\\sample.csv\")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "157486d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     AppleSupport causing the reply to be disregard...\n",
       "1     105835 Your business means a lot to us Please ...\n",
       "2     76328 I really hope you all change but Im sure...\n",
       "3     105836 LiveChat is online at the moment  https...\n",
       "4     VirginTrains see attached error message Ive tr...\n",
       "                            ...                        \n",
       "88    105860 I wish Amazon had an option of where I ...\n",
       "89    They reschedule my shit for tomorrow httpstcoR...\n",
       "90    105861 Hey Sara sorry to hear of the issues yo...\n",
       "91    Tesco bit of both  finding the layout cumberso...\n",
       "92    105861 If that doesnt help please DM your full...\n",
       "Name: text, Length: 93, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[\"text\"].apply(remove_punctuation_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff8498a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119237</td>\n",
       "      <td>105834</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 06:55:44 +0000 2017</td>\n",
       "      <td>AppleSupport causing the reply to be disregard...</td>\n",
       "      <td>119236</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119238</td>\n",
       "      <td>ChaseSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Oct 11 13:25:49 +0000 2017</td>\n",
       "      <td>105835 Your business means a lot to us Please ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119239</td>\n",
       "      <td>105835</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 13:00:09 +0000 2017</td>\n",
       "      <td>76328 I really hope you all change but Im sure...</td>\n",
       "      <td>119238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119240</td>\n",
       "      <td>VirginTrains</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 10 15:16:08 +0000 2017</td>\n",
       "      <td>105836 LiveChat is online at the moment  https...</td>\n",
       "      <td>119241</td>\n",
       "      <td>119242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119241</td>\n",
       "      <td>105836</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 10 15:17:21 +0000 2017</td>\n",
       "      <td>VirginTrains see attached error message Ive tr...</td>\n",
       "      <td>119243</td>\n",
       "      <td>119240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>119330</td>\n",
       "      <td>105859</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 13:50:42 +0000 2017</td>\n",
       "      <td>105860 I wish Amazon had an option of where I ...</td>\n",
       "      <td>119329</td>\n",
       "      <td>119331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>119331</td>\n",
       "      <td>105860</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 13:47:14 +0000 2017</td>\n",
       "      <td>They reschedule my shit for tomorrow httpstcoR...</td>\n",
       "      <td>119330</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>119332</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Oct 11 13:34:06 +0000 2017</td>\n",
       "      <td>105861 Hey Sara sorry to hear of the issues yo...</td>\n",
       "      <td>119333</td>\n",
       "      <td>119334.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>119333</td>\n",
       "      <td>105861</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 14:05:18 +0000 2017</td>\n",
       "      <td>Tesco bit of both  finding the layout cumberso...</td>\n",
       "      <td>119335,119336</td>\n",
       "      <td>119332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>119335</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Oct 11 15:38:07 +0000 2017</td>\n",
       "      <td>105861 If that doesnt help please DM your full...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119333.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    tweet_id     author_id  inbound                      created_at  \\\n",
       "0     119237        105834     True  Wed Oct 11 06:55:44 +0000 2017   \n",
       "1     119238  ChaseSupport    False  Wed Oct 11 13:25:49 +0000 2017   \n",
       "2     119239        105835     True  Wed Oct 11 13:00:09 +0000 2017   \n",
       "3     119240  VirginTrains    False  Tue Oct 10 15:16:08 +0000 2017   \n",
       "4     119241        105836     True  Tue Oct 10 15:17:21 +0000 2017   \n",
       "..       ...           ...      ...                             ...   \n",
       "88    119330        105859     True  Wed Oct 11 13:50:42 +0000 2017   \n",
       "89    119331        105860     True  Wed Oct 11 13:47:14 +0000 2017   \n",
       "90    119332         Tesco    False  Wed Oct 11 13:34:06 +0000 2017   \n",
       "91    119333        105861     True  Wed Oct 11 14:05:18 +0000 2017   \n",
       "92    119335         Tesco    False  Wed Oct 11 15:38:07 +0000 2017   \n",
       "\n",
       "                                                 text response_tweet_id  \\\n",
       "0   AppleSupport causing the reply to be disregard...            119236   \n",
       "1   105835 Your business means a lot to us Please ...               NaN   \n",
       "2   76328 I really hope you all change but Im sure...            119238   \n",
       "3   105836 LiveChat is online at the moment  https...            119241   \n",
       "4   VirginTrains see attached error message Ive tr...            119243   \n",
       "..                                                ...               ...   \n",
       "88  105860 I wish Amazon had an option of where I ...            119329   \n",
       "89  They reschedule my shit for tomorrow httpstcoR...            119330   \n",
       "90  105861 Hey Sara sorry to hear of the issues yo...            119333   \n",
       "91  Tesco bit of both  finding the layout cumberso...     119335,119336   \n",
       "92  105861 If that doesnt help please DM your full...               NaN   \n",
       "\n",
       "    in_response_to_tweet_id  \n",
       "0                       NaN  \n",
       "1                  119239.0  \n",
       "2                       NaN  \n",
       "3                  119242.0  \n",
       "4                  119240.0  \n",
       "..                      ...  \n",
       "88                 119331.0  \n",
       "89                      NaN  \n",
       "90                 119334.0  \n",
       "91                 119332.0  \n",
       "92                 119333.0  \n",
       "\n",
       "[93 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[\"text\"]=b[\"text\"].apply(remove_punctuation_2)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df2a8b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>119305</td>\n",
       "      <td>105854</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 13:49:52 +0000 2017</td>\n",
       "      <td>AskSpectrum Its just in my yard Ive called 45 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>119327</td>\n",
       "      <td>HPSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Oct 11 13:36:36 +0000 2017</td>\n",
       "      <td>105858 Hi Agoura thanks for tweeting Please re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>119296</td>\n",
       "      <td>105850</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 13:55:48 +0000 2017</td>\n",
       "      <td>SouthwestAir I am Thank you for the answer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>119297</td>\n",
       "      <td>105850</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 13:34:46 +0000 2017</td>\n",
       "      <td>southwestair Just curiouswill I get the compan...</td>\n",
       "      <td>119295</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119240</td>\n",
       "      <td>VirginTrains</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 10 15:16:08 +0000 2017</td>\n",
       "      <td>105836 LiveChat is online at the moment  https...</td>\n",
       "      <td>119241</td>\n",
       "      <td>119242.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tweet_id     author_id  inbound                      created_at  \\\n",
       "66    119305        105854     True  Wed Oct 11 13:49:52 +0000 2017   \n",
       "85    119327     HPSupport    False  Wed Oct 11 13:36:36 +0000 2017   \n",
       "56    119296        105850     True  Wed Oct 11 13:55:48 +0000 2017   \n",
       "57    119297        105850     True  Wed Oct 11 13:34:46 +0000 2017   \n",
       "3     119240  VirginTrains    False  Tue Oct 10 15:16:08 +0000 2017   \n",
       "\n",
       "                                                 text response_tweet_id  \\\n",
       "66  AskSpectrum Its just in my yard Ive called 45 ...               NaN   \n",
       "85  105858 Hi Agoura thanks for tweeting Please re...               NaN   \n",
       "56         SouthwestAir I am Thank you for the answer               NaN   \n",
       "57  southwestair Just curiouswill I get the compan...            119295   \n",
       "3   105836 LiveChat is online at the moment  https...            119241   \n",
       "\n",
       "    in_response_to_tweet_id  \n",
       "66                 119304.0  \n",
       "85                 119328.0  \n",
       "56                 119295.0  \n",
       "57                      NaN  \n",
       "3                  119242.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e42ca96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ea2f061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sinha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sinha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sinha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b627659d",
   "metadata": {},
   "source": [
    "### Chat Word Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d5c616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words={'AFAIK': 'As Far As I Know',\n",
    "'AFK': 'Away From Keyboard',\n",
    "'ASAP': 'As Soon As Possible',\n",
    "'ATK': 'At The Keyboard',\n",
    "'ATM': 'At The Moment',\n",
    "'A3': 'Anytime, Anywhere, Anyplace',\n",
    "'BAK': 'Back At Keyboard',\n",
    "'BBL': 'Be Back Later',\n",
    "'BBS': 'Be Back Soon',\n",
    "'BFN': 'Bye For Now',\n",
    "'B4N': 'Bye For Now',\n",
    "'BRB': 'Be Right Back',\n",
    "'BRT': 'Be Right There',\n",
    "'BTW': 'By The Way',\n",
    "'B4': 'Before',\n",
    "'CU': 'See You',\n",
    "'CUL8R': 'See You Later',\n",
    "'CYA': 'See You',\n",
    "'FAQ': 'Frequently Asked Questions',\n",
    "'FC': 'Fingers Crossed',\n",
    "'FWIW': \"For What It's Worth\",\n",
    "'FYI': 'For Your Information',\n",
    "'GAL': 'Get A Life',\n",
    "'GG': 'Good Game',\n",
    "'GN': 'Good Night',\n",
    "'GMTA': 'Great Minds Think Alike',\n",
    "'GR8': 'Great!',\n",
    "'G9': 'Genius',\n",
    "'IC': 'I See',\n",
    "'ICQ': 'I Seek you (also a chat program)',\n",
    "'ILU': 'ILU: I Love You',\n",
    "'IMHO': 'In My Honest/Humble Opinion',\n",
    "'IMO': 'In My Opinion',\n",
    "'IOW': 'In Other Words',\n",
    "'IMO': 'In My Opinion',\n",
    "'IOW': 'In Other Words',\n",
    "'IRL': 'In Real Life',\n",
    "'KISS': 'Keep It Simple, Stupid',\n",
    "'LDR': 'Long Distance Relationship',\n",
    "'LMAO': 'Laugh My A .. Off',\n",
    "'LOL': 'Laughing Out Loud',\n",
    "'LTNS': 'Long Time No See',\n",
    "'L8R': 'Later',\n",
    "'MTE': 'My Thoughts Exactly',\n",
    "'M8': 'Mate',\n",
    "'NRN': 'No Reply Necessary',\n",
    "'OIC': 'Oh I See',\n",
    "'PITA': 'Pain In The A .. ',\n",
    "'PRT': 'Party',\n",
    "'PRW': 'Parents Are Watching',\n",
    "'ROFL': 'Rolling On The Floor Laughing',\n",
    "'ROFLOL': 'Rolling On The Floor Laughing Out Loud',\n",
    "'ROTFLMAO': 'Rolling On The Floor Laughing My A .. Off',\n",
    "'SK8': 'Skate',\n",
    "'STATS': 'Your sex and age',\n",
    "'ASL': 'Age, Sex, Location',\n",
    "'THX': 'Thank You',\n",
    "'TTFN': 'Ta-Ta For Now!',\n",
    "'TTYL': 'Talk To You Later',\n",
    "'U': 'You',\n",
    "'U2': 'You Too',\n",
    "'U4E': 'Yours For Ever',\n",
    "'WB': 'Welcome Back',\n",
    "'WTF': 'What The F ...,',\n",
    "'WTG': 'Way To Go!',\n",
    "'WUF': 'Where Are You From?',\n",
    "'W8': 'Wait ... ',\n",
    "'7K': 'Sick :- D Laugher'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6559f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversion(text):\n",
    "    new_text = []\n",
    "    for w in text.split() :\n",
    "        if w.upper() in chat_words:\n",
    "            new_text.append(chat_words[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "            \n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77617307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>119302</td>\n",
       "      <td>105842</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 13:47:24 +0000 2017</td>\n",
       "      <td>BritishAirways Thanks for your answer Response...</td>\n",
       "      <td>119303</td>\n",
       "      <td>119266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>119243</td>\n",
       "      <td>VirginTrains</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 10 15:25:14 +0000 2017</td>\n",
       "      <td>105836 Have you tried from another device Miri...</td>\n",
       "      <td>119244</td>\n",
       "      <td>119241.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>119245</td>\n",
       "      <td>VirginTrains</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 10 15:33:22 +0000 2017</td>\n",
       "      <td>105836 Its working OK from here Miriam Does th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119244.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>119327</td>\n",
       "      <td>HPSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Oct 11 13:36:36 +0000 2017</td>\n",
       "      <td>105858 Hi Agoura thanks for tweeting Please re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>119283</td>\n",
       "      <td>105847</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 12:37:46 +0000 2017</td>\n",
       "      <td>SpotifyCares ive been having issues with playb...</td>\n",
       "      <td>119281</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tweet_id     author_id  inbound                      created_at  \\\n",
       "63    119302        105842     True  Wed Oct 11 13:47:24 +0000 2017   \n",
       "5     119243  VirginTrains    False  Tue Oct 10 15:25:14 +0000 2017   \n",
       "7     119245  VirginTrains    False  Tue Oct 10 15:33:22 +0000 2017   \n",
       "85    119327     HPSupport    False  Wed Oct 11 13:36:36 +0000 2017   \n",
       "48    119283        105847     True  Wed Oct 11 12:37:46 +0000 2017   \n",
       "\n",
       "                                                 text response_tweet_id  \\\n",
       "63  BritishAirways Thanks for your answer Response...            119303   \n",
       "5   105836 Have you tried from another device Miri...            119244   \n",
       "7   105836 Its working OK from here Miriam Does th...               NaN   \n",
       "85  105858 Hi Agoura thanks for tweeting Please re...               NaN   \n",
       "48  SpotifyCares ive been having issues with playb...            119281   \n",
       "\n",
       "    in_response_to_tweet_id  \n",
       "63                 119266.0  \n",
       "5                  119241.0  \n",
       "7                  119244.0  \n",
       "85                 119328.0  \n",
       "48                      NaN  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[\"text\"]=b[\"text\"].apply(chat_conversion)\n",
    "b.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "464a327c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I will be Away From Keyboard for a while. Be Back Later'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion(\"I will be AFK for a while. BBL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da8616c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You Too . Be Back Soon , Yours For Ever'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion(\"U2 . BBS , U4E\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89f190f",
   "metadata": {},
   "source": [
    "### Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73678b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6202973b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I have a dream that one day this nation will rise up and live out the true meaning of its creed: 'He hold these truths to be self-evident, thatIMDB Dataset.is\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_text = \"I havv a dreem that one day this nation will rise up and live out the true meaning of its creed: 'We hold these truths to be self-evident, that\"\"IMDB Dataset.csv\"\n",
    "text_blob = TextBlob(incorrect_text)\n",
    "text_blob.correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5575bd20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c28fe10c",
   "metadata": {},
   "source": [
    "### Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "126bd5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sinha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d258a882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')\n",
    "# stopwords.words('spanish') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f05dd2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = new_text[ : ]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e6b51ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This   sample sentence   stop words.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(\"This is a sample sentence with some stop words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf136459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. <br /><br />the...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd98beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"review\"].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0f03cf",
   "metadata": {},
   "source": [
    "### Handling Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63207c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"            # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"            # symbols & piptographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"            # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"            # flags (i0S)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b22b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a movie...'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"This is a movie...😁😁😁😁😁😍😍😒💕❤️😊🙌\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe7cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a movie...:beaming_face_with_smiling_eyes::beaming_face_with_smiling_eyes::beaming_face_with_smiling_eyes::beaming_face_with_smiling_eyes: :beaming_face_with_smiling_eyes::smiling_face_with_heart-eyes::smiling_face_with_heart-eyes::unamused_face:'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import emoji\n",
    "emoji.demojize(\"This is a movie...😁😁😁😁 😁😍😍😒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c64840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is game...:beaming_face_with_smiling_eyes::beaming_face_with_smiling_eyes::beaming_face_with_smiling_eyes::beaming_face_with_smiling_eyes: :unamused_face::two_hearts::beaming_face_with_smiling_eyes::smiling_face_with_heart-eyes::smiling_face_with_heart-eyes::unamused_face:\n"
     ]
    }
   ],
   "source": [
    "print(emoji.demojize(\"This is game...😁😁😁😁 😒💕😁😍😍😒\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436af7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b51c36a9",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd70166e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'am',\n",
       " 'going',\n",
       " 'to',\n",
       " 'the',\n",
       " 'market',\n",
       " 'today.',\n",
       " 'I',\n",
       " 'will',\n",
       " 'buy',\n",
       " 'some',\n",
       " 'fruits',\n",
       " 'and',\n",
       " 'vegetables.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=\"I am going to the market today. I will buy some fruits and vegetables.\" \n",
    "s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a05931b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am going to the market today',\n",
       " ' and going to move',\n",
       " '\\\\ to the next step.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=\"I am going to the market today, and going to move,\\ to the next step.\"\n",
    "p.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acf34bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'going', 'to', 'delhi!']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# problem with split function\n",
    "p1=\"i am going to delhi!\"\n",
    "p1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f414a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i am going to delhi! and i will be? back soon']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2=\"i am going to delhi! and i will be? back soon\"\n",
    "p2.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf2536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b307a0f8",
   "metadata": {},
   "source": [
    "2. Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbeef24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "sent3 = 'I am going to delhi!'\n",
    "tokens = re.findall(\"[\\w']+\", sent3)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92830e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Lorem Ipsum is simply dummy text of the printing and typesetting industry?\\nLorem Ipsum has been the industry's standard dummy text ever since the 1500s,\\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry?\n",
    "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s,\n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
    "sentences = re.compile('[ .!? ] ').split(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75316fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03d297bf",
   "metadata": {},
   "source": [
    "3. NLTK   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb01d0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\subhadip\n",
      "[nltk_data]     sinha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c406ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'am',\n",
       " 'going',\n",
       " 'to',\n",
       " 'delhi',\n",
       " '!',\n",
       " 'and',\n",
       " 'I',\n",
       " 'will',\n",
       " 'be',\n",
       " '?',\n",
       " 'back',\n",
       " 'soon',\n",
       " '!']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l='I am going to delhi! and I will be? back soon!'\n",
    "word_tokenize(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01405cff",
   "metadata": {},
   "source": [
    "4. Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac3345a",
   "metadata": {},
   "source": [
    "This ts best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9352e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_tokenize\n",
    "# This function is used to split a text into sentences.\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e36716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "from spacy.cli import download\n",
    "\n",
    "download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aed773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "am\n",
      "going\n",
      "to\n",
      "the\n",
      "market\n",
      "today\n",
      ",\n",
      "and\n",
      "going\n",
      "to\n",
      "move,\\\n",
      "to\n",
      "the\n",
      "next\n",
      "step\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(p)\n",
    "doc2 = nlp(p1)\n",
    "doc3 = nlp(p2)\n",
    "doc4 = nlp(s)\n",
    "\n",
    "for token in doc1:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203f8ba7",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bde663",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\"In grammar, inflection is the modification of a word to\n",
    "express different grammatical categories such as tense,\n",
    "case, voice, aspect, person, number, gender, and mood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6813c285",
   "metadata": {},
   "source": [
    "'Stemming is the process of reducing inflection in words\n",
    "to their root forms such as mapping a group of words to\n",
    "the same stem even if the stem itself is not a valid word in\n",
    "\n",
    "the Language.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be7cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stem_word(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0109eacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"walk walks walking walked\"\n",
    "stem_word(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6dea5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probably the best movie I have ever seen!\n"
     ]
    }
   ],
   "source": [
    "text=\"probably the best movie I have ever seen!\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a45cf6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probabl the best movi i have ever seen!'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_word(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cbe087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d235d6ff",
   "metadata": {},
   "source": [
    "\"Stemming is the process of reducing inflection in words\n",
    "to their root forms such as mapping a group of words to\n",
    "the same stem even if the stem itself is not a valid word in\n",
    "\n",
    "the Language.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82404c6",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1f8d78",
   "metadata": {},
   "source": [
    "Lemmatization, unlike Stemming, reduces the inflected\n",
    "words properly ensuring that the root word belongs to\n",
    "the language. In Lemmatization root word is called\n",
    "Lemma. A lemma (plural lemmas or lemmata) is the\n",
    "canonical form, dictionary form, or citation form of a set\n",
    "of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b123ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "He                  He                  \n",
      "was                 wa                  \n",
      "running             running             \n",
      "and                 and                 \n",
      "eating              eating              \n",
      "at                  at                  \n",
      "same                same                \n",
      "time                time                \n",
      "He                  He                  \n",
      "has                 ha                  \n",
      "bad                 bad                 \n",
      "habit               habit               \n",
      "of                  of                  \n",
      "swimming            swimming            \n",
      "after               after               \n",
      "playing             playing             \n",
      "long                long                \n",
      "hours               hour                \n",
      "in                  in                  \n",
      "the                 the                 \n",
      "Sun                 Sun                 \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "sentence = \"He was running and eating at: same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
    "pundtuations=\" ?:!. , ;\"\n",
    "sentence_words = nltk.word_tokenize(sentence)\n",
    "for word in sentence_words:\n",
    "    if word in pundtuations:\n",
    "        sentence_words.remove(word)\n",
    "\n",
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6d4fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd07b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leammatization is slow staming is fart \n",
    "\n",
    "# lemmatization is the process of converting a word to its base or root form.\n",
    "# Stemming is the process of reducing a word to its root form by removing suffixes and prefixes.\n",
    "# Stemming is faster than lemmatization but lemmatization gives better results.\n",
    "\n",
    "# when use lemmatization use :- user ko output dekhana haa\n",
    "# when use stemming use :- user ko output dekhana nahi haa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac5b2d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTHON---3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
