{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65f02709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef5387d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv(r'D:\\CODING\\PYTHON\\NLP\\IMDB Dataset_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf5b32e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = temp_df.iloc[:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcca0d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa7caeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_30628\\3006716147.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop_duplicates(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5aa873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_tags(raw_text):\n",
    "    cleaned_text = re.sub(re.compile('<.*?>'), '', raw_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3ef1d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_30628\\2336150696.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['review'] = df['review'].apply(remove_tags)\n"
     ]
    }
   ],
   "source": [
    "df['review'] = df['review'].apply(remove_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81f77af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_30628\\740760900.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['review'] = df['review'].apply(lambda x:x.lower())\n"
     ]
    }
   ],
   "source": [
    "df['review'] = df['review'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc2b2de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_30628\\2826946130.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['review'] = df['review'].apply(lambda x: [item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw_list = stopwords.words('english')\n",
    "\n",
    "df['review'] = df['review'].apply(lambda x: [item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fb66170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       one reviewers mentioned watching 1 oz episode ...\n",
       "1       wonderful little production. filming technique...\n",
       "2       thought wonderful way spend time hot summer we...\n",
       "3       basically there's family little boy (jake) thi...\n",
       "4       petter mattei's \"love time money\" visually stu...\n",
       "                              ...                        \n",
       "5995    first movie ever saw ashley judd first film vi...\n",
       "5996    recently saw movie hopes seeing accurate portr...\n",
       "5997    remember watching movie young, could recall ti...\n",
       "5998    annie's wig look good. cute pretty enough play...\n",
       "5999    movies viewed almost 60 years later, yet remai...\n",
       "Name: review, Length: 5997, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e4ac19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "# \n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be405746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function tokenizes the text into sentences \n",
    "\n",
    "from nltk import sent_tokenize,word_tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "# import gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0077c32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the sentences into words\n",
    "# This function converts sentences into a list of words\n",
    "# This is useful for further processing and analysis\n",
    "# It helps in preparing the text data for machine learning models\n",
    "# This function is essential for text preprocessing\n",
    "\n",
    "story = []\n",
    "for doc in df['review']:\n",
    "    raw_sent = sent_tokenize(doc)\n",
    "    for sent in raw_sent:\n",
    "        story.append(simple_preprocess(sent))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb22339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Word2Vec model\n",
    "# This model learns word embeddings from the text data\n",
    "# It captures the semantic relationships between words\n",
    "# This is useful for various NLP tasks such as text classification, sentiment analysis, and more\n",
    "# This model is trained on the tokenized sentences\n",
    "# by default vector size is 100, but we can change it\n",
    "# This model uses a sliding window of size 5 to learn the context of words\n",
    "\n",
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "867aaf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the vocabulary for the Word2Vec model\n",
    "# This step is essential for training the model\n",
    "# It allows the model to learn the relationships between words in the text data\n",
    "# This is a crucial step in the Word2Vec training process\n",
    "\n",
    "model.build_vocab(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2484c259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3540362, 3769310)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Word2Vec model\n",
    "# This step trains the model on the tokenized sentences\n",
    "# It allows the model to learn the word embeddings based on the context of words in the text data\n",
    "# The model will learn to predict the context of a word given its surrounding words\n",
    "\n",
    "model.train(story, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e303a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25360"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the vocabulary size of the Word2Vec model\n",
    "# This gives us the number of unique words in the model's vocabulary\n",
    "# This is useful for understanding the model's coverage of the text data\n",
    "# This can help in evaluating the model's performance and its ability to generalize to unseen data\n",
    "\n",
    "len(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e35574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes the document vector for a given document\n",
    "# It takes a document as input, removes out-of-vocabulary words, and returns the mean\n",
    "# of the word vectors for the remaining words\n",
    "# This is useful for converting text data into numerical representations\n",
    "# This function is essential for text classification tasks\n",
    "# It helps in creating a fixed-size vector representation of variable-length documents\n",
    "\n",
    "\n",
    "\n",
    "def document_vector(doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc.split() if word in model.wv.index_to_key]\n",
    "    return np.mean(model.wv[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f17deef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.15418196,  0.5057261 ,  0.23694786,  0.14975455, -0.06969841,\n",
       "       -0.50280553,  0.09809154,  0.73823863, -0.45555404, -0.23907205,\n",
       "       -0.17694281, -0.5500562 ,  0.05297895,  0.18089019,  0.08432296,\n",
       "       -0.43438575, -0.01295695, -0.43371964, -0.07964446, -0.7332231 ,\n",
       "        0.24429756,  0.15083466,  0.30064094, -0.30927008, -0.13727956,\n",
       "       -0.06077412, -0.25409055, -0.27741894, -0.31064788, -0.14181776,\n",
       "        0.4254479 ,  0.02412035,  0.0534478 , -0.3915822 , -0.12990966,\n",
       "        0.47061905, -0.01361409, -0.219377  , -0.30548164, -0.8787739 ,\n",
       "       -0.01502748, -0.48016235, -0.03032766,  0.10108441,  0.31130746,\n",
       "       -0.09495999, -0.45189232, -0.00714784,  0.07962143,  0.23397888,\n",
       "        0.13204578, -0.26287115, -0.22044665, -0.08311336, -0.3377041 ,\n",
       "        0.20476297,  0.3633046 ,  0.09289724, -0.4213441 ,  0.10623223,\n",
       "        0.00498722,  0.1213153 , -0.10336146, -0.10098853, -0.45451337,\n",
       "        0.31141734,  0.25569165,  0.2290632 , -0.52143466,  0.28831822,\n",
       "       -0.17804688,  0.08214173,  0.5315543 , -0.02748826,  0.4119099 ,\n",
       "        0.25406978,  0.00415578, -0.12946942, -0.33808374,  0.1034632 ,\n",
       "       -0.12434865, -0.1546581 , -0.24840519,  0.5924235 ,  0.13105826,\n",
       "       -0.0167994 , -0.11270688,  0.5018291 ,  0.60112625,  0.3099803 ,\n",
       "        0.27806896,  0.23837467,  0.14182106, -0.05839423,  0.793077  ,\n",
       "        0.24372382,  0.16927548, -0.53482026,  0.25702262,  0.01263153],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying the document vector for the first review\n",
    "# 100 dimensional vector representation of the first review\n",
    "\n",
    "document_vector(df['review'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3457d63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"one reviewers mentioned watching 1 oz episode hooked. right, exactly happened me.the first thing struck oz brutality unflinching scenes violence, set right word go. trust me, show faint hearted timid. show pulls punches regards drugs, sex violence. hardcore, classic use word.it called oz nickname given oswald maximum security state penitentary. focuses mainly emerald city, experimental section prison cells glass fronts face inwards, privacy high agenda. em city home many..aryans, muslims, gangstas, latinos, christians, italians, irish more....so scuffles, death stares, dodgy dealings shady agreements never far away.i would say main appeal show due fact goes shows dare. forget pretty pictures painted mainstream audiences, forget charm, forget romance...oz mess around. first episode ever saw struck nasty surreal, say ready it, watched more, developed taste oz, got accustomed high levels graphic violence. violence, injustice (crooked guards who'll sold nickel, inmates who'll kill order get away it, well mannered, middle class inmates turned prison bitches due lack street skills prison experience) watching oz, may become comfortable uncomfortable viewing....thats get touch darker side.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29d97c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tqdm for progress bar visualization\n",
    "# This is useful for tracking the progress of long-running operationsq\n",
    "\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5802ab7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5997/5997 [04:49<00:00, 20.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# Creating document vectors for all reviews\n",
    "# This step converts each review into a fixed-size vector representation\n",
    "# It helps in preparing the data for machine learning models\n",
    "# This function is essential for text classification tasks\n",
    "# It helps in creating a fixed-size vector representation of variable-length documents\n",
    "# This is useful for tracking the progress of long-running operations\n",
    "\n",
    "X = []\n",
    "for doc in tqdm(df['review'].values):\n",
    "    X.append(document_vector(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8ac1c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the list of document vectors into a NumPy array\n",
    "# This is useful for further processing and analysis\n",
    "# This allows us to work with the document vectors in a structured format\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a730b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15418196,  0.5057261 ,  0.23694786, ..., -0.53482026,\n",
       "         0.25702262,  0.01263153],\n",
       "       [-0.12471879,  0.44413525,  0.11436008, ..., -0.6722881 ,\n",
       "         0.20132318,  0.09869701],\n",
       "       [-0.12829684,  0.5391613 ,  0.20611449, ..., -0.60511035,\n",
       "         0.23407303, -0.03036152],\n",
       "       ...,\n",
       "       [-0.17182101,  0.49192736,  0.30103138, ..., -0.58288723,\n",
       "         0.20834984, -0.08847344],\n",
       "       [-0.16785957,  0.39189914,  0.26536083, ..., -0.5877873 ,\n",
       "         0.18216936,  0.09898672],\n",
       "       [-0.08609844,  0.556823  ,  0.30097803, ..., -0.6836062 ,\n",
       "         0.24791956, -0.05595976]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aab60576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.15418196,  0.5057261 ,  0.23694786,  0.14975455, -0.06969841,\n",
       "       -0.50280553,  0.09809154,  0.73823863, -0.45555404, -0.23907205,\n",
       "       -0.17694281, -0.5500562 ,  0.05297895,  0.18089019,  0.08432296,\n",
       "       -0.43438575, -0.01295695, -0.43371964, -0.07964446, -0.7332231 ,\n",
       "        0.24429756,  0.15083466,  0.30064094, -0.30927008, -0.13727956,\n",
       "       -0.06077412, -0.25409055, -0.27741894, -0.31064788, -0.14181776,\n",
       "        0.4254479 ,  0.02412035,  0.0534478 , -0.3915822 , -0.12990966,\n",
       "        0.47061905, -0.01361409, -0.219377  , -0.30548164, -0.8787739 ,\n",
       "       -0.01502748, -0.48016235, -0.03032766,  0.10108441,  0.31130746,\n",
       "       -0.09495999, -0.45189232, -0.00714784,  0.07962143,  0.23397888,\n",
       "        0.13204578, -0.26287115, -0.22044665, -0.08311336, -0.3377041 ,\n",
       "        0.20476297,  0.3633046 ,  0.09289724, -0.4213441 ,  0.10623223,\n",
       "        0.00498722,  0.1213153 , -0.10336146, -0.10098853, -0.45451337,\n",
       "        0.31141734,  0.25569165,  0.2290632 , -0.52143466,  0.28831822,\n",
       "       -0.17804688,  0.08214173,  0.5315543 , -0.02748826,  0.4119099 ,\n",
       "        0.25406978,  0.00415578, -0.12946942, -0.33808374,  0.1034632 ,\n",
       "       -0.12434865, -0.1546581 , -0.24840519,  0.5924235 ,  0.13105826,\n",
       "       -0.0167994 , -0.11270688,  0.5018291 ,  0.60112625,  0.3099803 ,\n",
       "        0.27806896,  0.23837467,  0.14182106, -0.05839423,  0.793077  ,\n",
       "        0.24372382,  0.16927548, -0.53482026,  0.25702262,  0.01263153],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying the shape of the document vectors\n",
    "# This gives us the number of documents and the dimensionality of the vectors\n",
    "\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6c0835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing LabelEncoder for encoding the sentiment labels\n",
    "# This is useful for converting categorical labels into numerical format\n",
    "# This is essential for training machine learning models\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "y = encoder.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec5ece01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9460495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90f10ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing RandomForestClassifier for training the model\n",
    "# This is a popular machine learning algorithm for classification tasks\n",
    "# It is an ensemble method that combines multiple decision trees to improve accuracy\n",
    "# This model is useful for text classification tasks\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e1a6d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7183333333333334"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0694c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4668778f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTHON---3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
